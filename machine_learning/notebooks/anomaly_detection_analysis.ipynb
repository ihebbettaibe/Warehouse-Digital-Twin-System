{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10ad137",
   "metadata": {},
   "source": [
    "# Warehouse Digital Twin - Anomaly Detection Analysis\n",
    "\n",
    "This notebook demonstrates the machine learning approach for anomaly detection in warehouse sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3747d",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Sensor Data for Testing\n",
    "\n",
    "First, let's generate some synthetic sensor data to test our anomaly detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(sensor_type, num_samples=1000, anomaly_percentage=5):\n",
    "    \"\"\"\n",
    "    Generate synthetic sensor data with anomalies\n",
    "    \n",
    "    Parameters:\n",
    "    - sensor_type: Type of sensor (temperature, humidity, etc.)\n",
    "    - num_samples: Number of data points to generate\n",
    "    - anomaly_percentage: Percentage of data that should be anomalous\n",
    "    \"\"\"\n",
    "    # Define normal ranges for different sensor types\n",
    "    normal_ranges = {\n",
    "        'temperature': {'mean': 25, 'std': 2.5, 'anomaly_factor': 3.5},\n",
    "        'humidity': {'mean': 50, 'std': 8, 'anomaly_factor': 3},\n",
    "        'pressure': {'mean': 1013, 'std': 5, 'anomaly_factor': 4},\n",
    "        'weight': {'mean': 2500, 'std': 500, 'anomaly_factor': 2.5},\n",
    "        'battery_level': {'mean': 75, 'std': 15, 'anomaly_factor': 3}\n",
    "    }\n",
    "    \n",
    "    if sensor_type not in normal_ranges:\n",
    "        raise ValueError(f\"Sensor type {sensor_type} not supported\")\n",
    "        \n",
    "    # Get parameters for this sensor type\n",
    "    params = normal_ranges[sensor_type]\n",
    "    \n",
    "    # Generate normal data\n",
    "    normal_count = int(num_samples * (100 - anomaly_percentage) / 100)\n",
    "    anomaly_count = num_samples - normal_count\n",
    "    \n",
    "    normal_data = np.random.normal(\n",
    "        params['mean'], \n",
    "        params['std'], \n",
    "        normal_count\n",
    "    )\n",
    "    \n",
    "    # Generate anomaly data (outside normal range)\n",
    "    anomaly_data = []\n",
    "    for _ in range(anomaly_count):\n",
    "        # Randomly choose high or low anomaly\n",
    "        if np.random.random() > 0.5:\n",
    "            # High anomaly\n",
    "            value = params['mean'] + (params['std'] * params['anomaly_factor'] * np.random.random())\n",
    "        else:\n",
    "            # Low anomaly\n",
    "            value = params['mean'] - (params['std'] * params['anomaly_factor'] * np.random.random())\n",
    "        anomaly_data.append(value)\n",
    "    \n",
    "    # Combine data and create labels (1 for normal, -1 for anomaly)\n",
    "    all_values = list(normal_data) + anomaly_data\n",
    "    all_labels = [1] * normal_count + [-1] * anomaly_count\n",
    "    \n",
    "    # Create timestamps (last 1000 minutes, one reading per minute)\n",
    "    timestamps = pd.date_range(\n",
    "        end=pd.Timestamp.now(), \n",
    "        periods=num_samples, \n",
    "        freq='T'\n",
    "    )\n",
    "    \n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'value': all_values,\n",
    "        'anomaly': all_labels\n",
    "    })\n",
    "    \n",
    "    # Shuffle the dataframe to mix normal and anomaly data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for a few sensor types\n",
    "sensor_types = ['temperature', 'humidity', 'pressure']\n",
    "sample_data = {}\n",
    "\n",
    "for sensor_type in sensor_types:\n",
    "    sample_data[sensor_type] = generate_sample_data(sensor_type, num_samples=1000, anomaly_percentage=5)\n",
    "    print(f\"Generated {len(sample_data[sensor_type])} samples for {sensor_type} sensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7d831d",
   "metadata": {},
   "source": [
    "Let's visualize the sample temperature data to see what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_data(df, sensor_type):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Plot all data points\n",
    "    plt.scatter(\n",
    "        df['timestamp'], \n",
    "        df['value'],\n",
    "        c=df['anomaly'].map({1: 'blue', -1: 'red'}),\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"{sensor_type} Sensor Readings with Anomalies\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(f\"{sensor_type.capitalize()} Value\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Normal'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Anomaly')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Also show a histogram of values\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Plot histograms for normal and anomaly data\n",
    "    sns.histplot(\n",
    "        df[df['anomaly'] == 1]['value'], \n",
    "        color='blue', \n",
    "        label='Normal',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    sns.histplot(\n",
    "        df[df['anomaly'] == -1]['value'], \n",
    "        color='red', \n",
    "        label='Anomaly',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Distribution of {sensor_type.capitalize()} Values\")\n",
    "    plt.xlabel(f\"{sensor_type.capitalize()} Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615447ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature data\n",
    "plot_sensor_data(sample_data['temperature'], 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd422c2f",
   "metadata": {},
   "source": [
    "## 2. Implementing Anomaly Detection with Isolation Forest\n",
    "\n",
    "Now let's implement the Isolation Forest algorithm for anomaly detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_isolation_forest(data, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Train an Isolation Forest model for anomaly detection\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame with sensor readings\n",
    "    - contamination: Expected proportion of anomalies\n",
    "    \n",
    "    Returns:\n",
    "    - Trained model and scaler\n",
    "    \"\"\"\n",
    "    # Extract the values and reshape for sklearn\n",
    "    X = data['value'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train Isolation Forest\n",
    "    model = IsolationForest(\n",
    "        n_estimators=100,\n",
    "        max_samples='auto',\n",
    "        contamination=contamination,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_scaled)\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b976456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, scaler, data):\n",
    "    \"\"\"\n",
    "    Evaluate model performance and compare with ground truth\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X = data['value'].values.reshape(-1, 1)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    predictions = model.predict(X_scaled)\n",
    "    scores = model.score_samples(X_scaled)\n",
    "    \n",
    "    # Add predictions to dataframe\n",
    "    results = data.copy()\n",
    "    results['predicted'] = predictions\n",
    "    results['anomaly_score'] = scores\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "    \n",
    "    cm = confusion_matrix(results['anomaly'], results['predicted'])\n",
    "    report = classification_report(results['anomaly'], results['predicted'])\n",
    "    accuracy = accuracy_score(results['anomaly'], results['predicted'])\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Plot actual anomalies\n",
    "    plt.scatter(\n",
    "        results['timestamp'],\n",
    "        results['value'],\n",
    "        c=results['anomaly'].map({1: 'blue', -1: 'red'}),\n",
    "        alpha=0.3,\n",
    "        label='Actual'\n",
    "    )\n",
    "    \n",
    "    # Plot predicted anomalies as circles\n",
    "    anomaly_indices = results[results['predicted'] == -1].index\n",
    "    plt.scatter(\n",
    "        results.iloc[anomaly_indices]['timestamp'],\n",
    "        results.iloc[anomaly_indices]['value'],\n",
    "        edgecolors='green',\n",
    "        facecolors='none',\n",
    "        s=80,\n",
    "        label='Predicted Anomaly'\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Actual vs Predicted Anomalies\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Sensor Value\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot anomaly scores\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(results['timestamp'], results['anomaly_score'])\n",
    "    \n",
    "    # Highlight anomalies\n",
    "    plt.scatter(\n",
    "        results.iloc[anomaly_indices]['timestamp'],\n",
    "        results.iloc[anomaly_indices]['anomaly_score'],\n",
    "        color='red',\n",
    "        label='Anomaly'\n",
    "    )\n",
    "    \n",
    "    # Draw threshold line\n",
    "    threshold = model.threshold_\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.4f}')\n",
    "    \n",
    "    plt.title(\"Anomaly Scores Over Time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Anomaly Score\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3464d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate model for temperature\n",
    "temp_model, temp_scaler = train_isolation_forest(sample_data['temperature'], contamination=0.05)\n",
    "temp_results = evaluate_model(temp_model, temp_scaler, sample_data['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a320122",
   "metadata": {},
   "source": [
    "## 3. Implementing Sliding Window Anomaly Detection\n",
    "\n",
    "A more realistic approach for streaming data is to use a sliding window technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_streaming_detection(data, window_size=100, step=10):\n",
    "    \"\"\"\n",
    "    Simulate detecting anomalies in streaming data using a sliding window\n",
    "    \"\"\"\n",
    "    sorted_data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    # Process data in chunks\n",
    "    for start_idx in range(0, len(sorted_data) - window_size, step):\n",
    "        end_idx = start_idx + window_size\n",
    "        \n",
    "        # Training window\n",
    "        train_window = sorted_data.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Next batch to predict\n",
    "        predict_window = sorted_data.iloc[end_idx:end_idx+step]\n",
    "        \n",
    "        if len(predict_window) == 0:\n",
    "            break\n",
    "            \n",
    "        # Train model on window\n",
    "        X_train = train_window['value'].values.reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        \n",
    "        model = IsolationForest(\n",
    "            n_estimators=100,\n",
    "            max_samples='auto',\n",
    "            contamination=0.05,\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_scaled)\n",
    "        \n",
    "        # Predict on next batch\n",
    "        X_pred = predict_window['value'].values.reshape(-1, 1)\n",
    "        X_pred_scaled = scaler.transform(X_pred)\n",
    "        \n",
    "        predictions = model.predict(X_pred_scaled)\n",
    "        scores = model.score_samples(X_pred_scaled)\n",
    "        \n",
    "        # Store results\n",
    "        batch_results = predict_window.copy()\n",
    "        batch_results['predicted'] = predictions\n",
    "        batch_results['anomaly_score'] = scores\n",
    "        batch_results['window_start'] = start_idx\n",
    "        batch_results['window_end'] = end_idx\n",
    "        \n",
    "        results = pd.concat([results, batch_results])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate streaming detection\n",
    "streaming_results = simulate_streaming_detection(sample_data['temperature'], window_size=100, step=25)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot actual values\n",
    "plt.scatter(\n",
    "    streaming_results['timestamp'],\n",
    "    streaming_results['value'],\n",
    "    c=streaming_results['anomaly'].map({1: 'blue', -1: 'red'}),\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "# Plot predicted anomalies\n",
    "anomaly_indices = streaming_results[streaming_results['predicted'] == -1].index\n",
    "plt.scatter(\n",
    "    streaming_results.iloc[anomaly_indices]['timestamp'],\n",
    "    streaming_results.iloc[anomaly_indices]['value'],\n",
    "    edgecolors='green',\n",
    "    facecolors='none',\n",
    "    s=80,\n",
    "    label='Predicted Anomaly'\n",
    ")\n",
    "\n",
    "plt.title(\"Streaming Anomaly Detection Results\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Streaming Detection Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(streaming_results['anomaly'], streaming_results['predicted']):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(streaming_results['anomaly'], streaming_results['predicted']))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(streaming_results['anomaly'], streaming_results['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c071842",
   "metadata": {},
   "source": [
    "## 4. Saving and Loading Models\n",
    "\n",
    "Let's demonstrate how to save and load models for production use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save models for different sensor types\n",
    "for sensor_type in sensor_types:\n",
    "    # Train model\n",
    "    model, scaler = train_isolation_forest(sample_data[sensor_type])\n",
    "    \n",
    "    # Save model and scaler\n",
    "    joblib.dump(model, f'models/{sensor_type}_model.pkl')\n",
    "    joblib.dump(scaler, f'models/{sensor_type}_scaler.pkl')\n",
    "    \n",
    "    print(f\"Saved model for {sensor_type}\")\n",
    "    \n",
    "# Test loading the model\n",
    "loaded_model = joblib.load('models/temperature_model.pkl')\n",
    "loaded_scaler = joblib.load('models/temperature_scaler.pkl')\n",
    "\n",
    "print(\"\\nModel loaded successfully\")\n",
    "\n",
    "# Test prediction with loaded model\n",
    "test_sample = np.array([[35.0]])  # An anomalous temperature\n",
    "test_scaled = loaded_scaler.transform(test_sample)\n",
    "prediction = loaded_model.predict(test_scaled)[0]\n",
    "score = loaded_model.score_samples(test_scaled)[0]\n",
    "\n",
    "print(f\"Test prediction for temperature=35.0: {'Anomaly' if prediction == -1 else 'Normal'} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4017f",
   "metadata": {},
   "source": [
    "## 5. Integration with the Digital Twin System\n",
    "\n",
    "The ML models trained here can be integrated with the Warehouse Digital Twin system in the following ways:\n",
    "\n",
    "1. **Offline Training:** Use this notebook to train initial models with historical data\n",
    "2. **Online Learning:** The `ml_detector.py` script performs online learning and adaptation\n",
    "3. **Real-time Anomaly Detection:** Anomalies are published to a dedicated Kafka topic\n",
    "4. **Dashboard Integration:** The dashboard can be enhanced to display ML-detected anomalies\n",
    "\n",
    "The key advantage of using machine learning for anomaly detection is that it can adapt to the normal patterns of the warehouse and detect subtle anomalies that rule-based systems might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of model performance for different sensor types\n",
    "performance_summary = {}\n",
    "\n",
    "for sensor_type in sensor_types:\n",
    "    print(f\"\\n==== Evaluating {sensor_type.upper()} sensor ====\\n\")\n",
    "    model, scaler = train_isolation_forest(sample_data[sensor_type])\n",
    "    results = evaluate_model(model, scaler, sample_data[sensor_type])\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(results['anomaly'], results['predicted'])\n",
    "    cm = confusion_matrix(results['anomaly'], results['predicted'])\n",
    "    \n",
    "    # True positives, false positives, etc.\n",
    "    tp = cm[1, 1] if cm.shape == (2, 2) else 0\n",
    "    fp = cm[0, 1] if cm.shape == (2, 2) else 0\n",
    "    tn = cm[0, 0] if cm.shape == (2, 2) else 0\n",
    "    fn = cm[1, 0] if cm.shape == (2, 2) else 0\n",
    "    \n",
    "    # Detection rate and false alarm rate\n",
    "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    performance_summary[sensor_type] = {\n",
    "        'accuracy': accuracy,\n",
    "        'detection_rate': detection_rate,\n",
    "        'false_alarm_rate': false_alarm_rate\n",
    "    }\n",
    "\n",
    "# Create performance summary table\n",
    "summary_df = pd.DataFrame(performance_summary).T\n",
    "summary_df = summary_df * 100  # Convert to percentages\n",
    "summary_df = summary_df.round(2)\n",
    "\n",
    "print(\"\\n===== Performance Summary =====\\n\")\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
